{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb173248",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, Conv2D, ReLU, BatchNormalization, Add, MaxPooling2D, Flatten, Dense, Softmax, Activation, GlobalAveragePooling2D, ZeroPadding2D\n",
    "from tensorflow.keras.optimizers import Adam, Nadam, SGD\n",
    "import numpy as np\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62384345",
   "metadata": {},
   "outputs": [
   ],
   "source": [
    "tf.__version__\n",
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9bb0ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataGenerator(start_index, stop_index):\n",
    "    def generator():\n",
    "        indexes = shuff[start_index : stop_index]\n",
    "        for i in indexes:\n",
    "            x = np.array(hdf5['Xs'][i])\n",
    "            y = np.array(hdf5['Ys'][i])\n",
    "            yield x, y\n",
    "    return generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97b334aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_steps: 178533, val_steps: 35706\n"
     ]
    }
   ],
   "source": [
    "hdf5 = h5py.File('./hdf5/dan_training_dataset.hdf5','r')\n",
    "batch_size = 64\n",
    "dataset_size = hdf5['Xs'].shape[0]\n",
    "val_start = 0.8\n",
    "val_stop = 1.0\n",
    "\n",
    "train_steps = int(dataset_size/batch_size)\n",
    "val_steps = int(dataset_size * (val_stop - val_start)/batch_size)\n",
    "print(f\"train_steps: {train_steps}, val_steps: {val_steps}\")\n",
    "shuff = np.arange(dataset_size)\n",
    "np.random.shuffle(shuff)\n",
    "\n",
    "data_gen = dataGenerator(start_index = 0, stop_index = int(dataset_size * val_start))\n",
    "dataset = tf.data.Dataset.from_generator(data_gen, \n",
    "                                         output_types=(tf.dtypes.float32, tf.dtypes.int32),\n",
    "                                         output_shapes=(tf.TensorShape((19,19,19)),tf.TensorShape((1))))\n",
    "dataset = dataset.batch(batch_size, drop_remainder=True)\n",
    "dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "data_gen_valid = dataGenerator(start_index=int(dataset_size * val_start),\n",
    "                               stop_index=int(dataset_size * val_stop))\n",
    "dataset_valid = tf.data.Dataset.from_generator(data_gen_valid, \n",
    "                                         output_types=(tf.dtypes.float32, tf.dtypes.int32),\n",
    "                                         output_shapes=(tf.TensorShape((19,19,19)),tf.TensorShape((1))))\n",
    "dataset_valid = dataset_valid.batch(batch_size, drop_remainder=True)\n",
    "dataset_valid = dataset_valid.prefetch(tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ebf5fcb",
   "metadata": {},
   "outputs": [
   ],
   "source": [
    "# resnet50\n",
    "def block1(x, filters, kernel_size=3, stride=1, conv_shortcut=False):\n",
    "    bn_axis=3\n",
    "    preact = Activation(\"relu\")(x)\n",
    "    if conv_shortcut:\n",
    "        shortcut = Conv2D(4 * filters, 1, strides=stride)(preact)\n",
    "    else:\n",
    "        shortcut = x\n",
    "    \n",
    "    x = Conv2D(filters, 1, strides=1, use_bias=False)(preact)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = ZeroPadding2D(padding=((1, 1), (1, 1)))(x)\n",
    "    x = Conv2D(\n",
    "        filters,\n",
    "        kernel_size,\n",
    "        strides=stride,\n",
    "        use_bias=False\n",
    "    )(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Conv2D(4 * filters, 1)(x)\n",
    "    x = Add()([shortcut, x])\n",
    "    return x\n",
    "\n",
    "def ResNet50(include_top=True,\n",
    "             input_tensor=None,\n",
    "             input_shape=None,\n",
    "             pooling=False):\n",
    "    inputs = Input(shape = input_shape)\n",
    "    x = block1(inputs, 256, conv_shortcut=True)\n",
    "    x = block1(x, 256)\n",
    "    x = block1(x, 256)\n",
    "    x = block1(x, 256)\n",
    "    x = block1(x, 256)\n",
    "    x = block1(x, 256)\n",
    "    x = block1(x, 256)\n",
    "    x = block1(x, 256)\n",
    "    x = block1(x, 256)\n",
    "    x = block1(x, 256)\n",
    "    x = block1(x, 256)\n",
    "    x = block1(x, 256)\n",
    "    x = block1(x, 256)\n",
    "    x = block1(x, 256)\n",
    "    x = block1(x, 256)\n",
    "    x = block1(x, 256)\n",
    "    x = block1(x, 256)\n",
    "    x = block1(x, 256)\n",
    "    x = block1(x, 256)\n",
    "    x = block1(x, 256)\n",
    "    x = block1(x, 256)\n",
    "    x = block1(x, 256)\n",
    "    x = block1(x, 256)\n",
    "    x = block1(x, 256)\n",
    "    x = block1(x, 256)\n",
    "    x = block1(x, 256)\n",
    "    x = block1(x, 256)\n",
    "    x = block1(x, 256)\n",
    "    x = block1(x, 256)\n",
    "    \n",
    "    x = GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "    x = Dense(361, activation='softmax', name='fc1000')(x)\n",
    "\n",
    "    model = Model(inputs, x, name='resnet50')\n",
    "    return model\n",
    "\n",
    "model = ResNet50(include_top=True,\n",
    "                 input_tensor=None,\n",
    "                 input_shape=(19, 19, 19),\n",
    "                 pooling=False)\n",
    "opt = Nadam(learning_rate = 0.0001)\n",
    "model.compile(optimizer = opt,\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c83b22c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# callback1 = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, \n",
    "#                                 patience=3, verbose=0, mode='min'\n",
    "#                                  , restore_best_weights=True)\n",
    "callback2 = tf.keras.callbacks.ModelCheckpoint('./models/model_dan_v2_b64_f256_l88_cor_{epoch:02d}_1.h5', \n",
    "#                                             monitor='val_accuracy', \n",
    "                                            verbose=0, save_best_only=False, save_weights_only=False, \n",
    "                                            mode='max', save_freq=\"epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44bcf17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = load_model('./models/model_dan_v2_b64_f256_l88_cor_01.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4d7f1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
   ],
   "source": [
    "history = model.fit(\n",
    "    dataset,\n",
    "    epochs = 500,\n",
    "#     steps_per_epoch = train_steps,\n",
    "    validation_data = dataset_valid,\n",
    "#     validation_steps = val_steps,\n",
    "    callbacks = [callback2]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee70e090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('./models/model_dan_v2_b64_f256_l88_cor_03_1.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
